
# ğŸ§  Hybrid Alignment Architecture

**Ein modulares Framework zur Kombination von Constitutional AI & Multi-Agent Critique.**  
Entwickelt, um robuste, nachvollziehbare und adaptive Alignment-Systeme zu ermÃ¶glichen.

---

## ğŸš€ Features

- YAML-basierte **Verfassung (Constitution)** mit auditierbaren Prinzipien
- Rollenbasierte Agentenarchitektur:
  - ğŸ¤– `SocraticAgent`: stellt tiefgehende Fragen
  - ğŸ˜ˆ `DevilAgent`: provoziert Exploits & Fehler
  - ğŸ§  `ArbiterAgent`: entscheidet bei WidersprÃ¼chen
  - ğŸ› ï¸ `EngineerAgent`: prÃ¼ft NÃ¼tzlichkeit & Umsetzbarkeit
  - ğŸ§½ `CleanUpAgent`: filtert schwache Argumente
- Bewertungslogik: VerfassungskonformitÃ¤t + epistemisches Feedback
- Meta-Aggregation zur Bewertung von Konsens und Vertrauensniveau
- FastAPI-Schnittstelle mit JSON-API fÃ¼r Analyse & Feedback
- VollstÃ¤ndig getestet mit `pytest`

---

## ğŸ“ Projektstruktur

```bash
hybrid_alignment_architecture/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ agents/                # Agentenrollen
â”‚   â”œâ”€â”€ core/                  # Verfassung, Bewertung, Meta-Logik
â”‚   â”œâ”€â”€ schemas/               # Datenmodelle
â”‚   â””â”€â”€ main.py                # FastAPI Entry-Point
â”œâ”€â”€ constitution/              # YAML-Verfassung
â”œâ”€â”€ tests/                     # pytest-Tests
â””â”€â”€ README.md


â¸»

ğŸ§ª Schnellstart

# AbhÃ¤ngigkeiten installieren
pip install -r requirements.txt

# Server starten
uvicorn app.main:app --reload

# Tests ausfÃ¼hren
pytest


â¸»

ğŸ” Beispielendpunkte (API)

Bewertung eines Textes:

POST /evaluate
{
  "text": "Das System darf niemals lÃ¼gen und muss ehrlich bleiben."
}

Aggregiertes Agentenfeedback:

POST /meta/aggregate
[
  {"agent_name": "A", "content": "ok", "epistemic_score": 0.7},
  {"agent_name": "B", "content": "ok", "epistemic_score": 0.4}
]


â¸»

ğŸ¤ Mitwirken

Dieses Projekt ist offen fÃ¼r Forschung, Red-Teaming, Interpretationsmodule und KI-Sicherheit.
Jeder Beitrag, der das Alignment robuster, ethischer oder testbarer macht, ist willkommen.

â¸»
